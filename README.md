# Transliteration_assignment

# Hindi â†’ Roman Transliteration using Character-Level GRU

This project implements a **lightweight character-level GRU encoderâ€“decoder model** that transliterates **Hindi words into Roman (Latin) script**.  
The model is trained from scratch using the **Dakshina transliteration dataset** and deployed as a live demo using **HuggingFace Spaces**.

---

## ğŸ”¹ What is Transliteration?

**Transliteration** is the process of converting text from one script to another **without changing the language**.

Example:

| Hindi | Roman |
|-------|--------|
| à¤¨à¤®à¤¸à¥à¤•à¤¾à¤° | namaskar |
| à¤˜à¤°à¥‹à¤‚ | gharon |
| à¤¸à¤«à¤¾à¤ˆ | safai |

This is **not translation** (meaning is unchanged).

---

## âœ… Model Overview

- **Architecture:** Character-level Seq2Seq (GRU Encoderâ€“Decoder)
- **Input:** Hindi word (Devanagari script)
- **Output:** Romanized word (Latin script)
- **Training Type:** Fully supervised
- **Special Tokens:** `<pad>`, `<sos>`, `<eos>`

### Model Hyperparameters

| Parameter | Value |
|----------|--------|
| Encoder Embedding | 128 |
| Decoder Embedding | 128 |
| Hidden Size | 256 |
| GRU Layers | 1 |
| Dropout | 0.2 |
| Optimizer | Adam |
| Learning Rate | 1e-3 |

---

## ğŸ“‚ Dataset

The dataset is built using the **Dakshina Hindi Lexicon Splits**:

- `hi.translit.sampled.train.tsv`
- `hi.translit.sampled.dev.tsv`
- `hi.translit.sampled.test.tsv`

Each row contains:


### Dataset Sizes

| Split | Samples |
|--------|----------|
| Train | 79,805 |
| Validation | 4,358 |
| Test | 4,502 |

âœ… Only **clean word-level data** is used  
âœ… Roman outputs are normalized to **lowercase aâ€“z only**

---

## ğŸ“Š Evaluation Metrics

- **Primary Metric:** Exact Match Word Accuracy  
- Accuracy is computed by comparing full predicted words with ground truth.

| Split | Accuracy |
|--------|----------|
| Validation | 25.56 % |
| Test | 24.57 % |

_(Fill these numbers after your final evaluation run)_

---

## âš¡ Inference Latency

Average inference time per word:

| Device | Latency |
|--------|----------|
| CPU | 3.329 ms / word |
| GPU | 2.921 ms / word |

_(Measured using random Hindi words from the training set)_

---

## ğŸŒ Live Demo (HuggingFace Spaces)

You can try sentence-level transliteration here:

ğŸ”— **HuggingFace Space:**  
`https://huggingface.co/spaces/harishwar017/YOUR_SPACE_NAME`

- Paste a **Hindi sentence**
- It is internally split into words
- Each word is transliterated
- Final Romanized sentence is returned with punctuation preserved

---

## ğŸ¤— Pretrained Model

The trained model and vocabularies are hosted on HuggingFace:

ğŸ”— **HuggingFace Model:**  
`https://huggingface.co/harishwar017/hindi-roman-gru`

Files included:
- `best_hindi_roman_gru.pt`
- `src_stoi.json`
- `tgt_stoi.json`

---

## ğŸ›  Project Structure

â”œâ”€â”€ app.py # Gradio app for HuggingFace Space
â”œâ”€â”€ train.py # Model training script
â”œâ”€â”€ data_prep.py # Dataset processing script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src_stoi.json
â”œâ”€â”€ tgt_stoi.json
â””â”€â”€ README.md

